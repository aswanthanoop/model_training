{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you a fan of Google or Microsoft?</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Both are excellent technology they are helpfu...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm not  a huge fan of Google, but I use it a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Google provides online related services and p...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, their services are good. I'm just not a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id                                            message  \\\n",
       "0                1              Are you a fan of Google or Microsoft?   \n",
       "1                1   Both are excellent technology they are helpfu...   \n",
       "2                1   I'm not  a huge fan of Google, but I use it a...   \n",
       "3                1   Google provides online related services and p...   \n",
       "4                1   Yeah, their services are good. I'm just not a...   \n",
       "\n",
       "                 sentiment  \n",
       "0   Curious to dive deeper  \n",
       "1   Curious to dive deeper  \n",
       "2   Curious to dive deeper  \n",
       "3   Curious to dive deeper  \n",
       "4   Curious to dive deeper  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_dataset = pd.read_csv(\"topical_chat.csv\")\n",
    "bot_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aswan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aswan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stopwords.words(\"english\")]\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_dataset[\"processed_message\"] = bot_dataset[\"message\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bot_dataset[\"processed_message\"]\n",
    "y = bot_dataset[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=100, padding=\"post\", truncating=\"post\")\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=100, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    #Dropout(0.5),\n",
    "    Dense(8, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 128)          640000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100, 128)          131584    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825672 (3.15 MB)\n",
      "Trainable params: 825672 (3.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\aswan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\aswan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3015/3015 [==============================] - 387s 127ms/step - loss: 1.4362 - accuracy: 0.4288 - val_loss: 1.4249 - val_accuracy: 0.4328\n",
      "Epoch 2/5\n",
      "3015/3015 [==============================] - 366s 122ms/step - loss: 1.4332 - accuracy: 0.4288 - val_loss: 1.4240 - val_accuracy: 0.4328\n",
      "Epoch 3/5\n",
      "3015/3015 [==============================] - 369s 122ms/step - loss: 1.4326 - accuracy: 0.4288 - val_loss: 1.4243 - val_accuracy: 0.4328\n",
      "Epoch 4/5\n",
      "3015/3015 [==============================] - 363s 120ms/step - loss: 1.4327 - accuracy: 0.4288 - val_loss: 1.4239 - val_accuracy: 0.4328\n",
      "Epoch 5/5\n",
      "3015/3015 [==============================] - 362s 120ms/step - loss: 1.4325 - accuracy: 0.4288 - val_loss: 1.4240 - val_accuracy: 0.4328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20d77a0c090>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_padded, y_train_encoded, epochs=5, batch_size=45, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1178/1178 [==============================] - 42s 36ms/step - loss: 1.4316 - accuracy: 0.4301\n",
      "Test accuracy: 0.4300881326198578\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded, y_test_encoded)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 891ms/step\n",
      "Predicted sentiment:  Curious to dive deeper\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    processed_text = preprocess_text(text)\n",
    "    sequence = tokenizer.texts_to_sequences([processed_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=100, padding=\"post\", truncating=\"post\")\n",
    "    sentiment_probabilities = model.predict(padded_sequence)\n",
    "    predicted_sentiment_id = np.argmax(sentiment_probabilities)\n",
    "    predicted_sentiment = label_encoder.inverse_transform([predicted_sentiment_id])[0]\n",
    "    return predicted_sentiment\n",
    "\n",
    "user_input = input(\"Enter a message: \")\n",
    "predicted_sentiment = predict_sentiment(user_input)\n",
    "print(\"Predicted sentiment:\", predicted_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rule_based_response(predicted_sentiment):\n",
    "    if predicted_sentiment == \"Happy\":\n",
    "        response = \"I'm glad to hear that you're feeling happy!\"\n",
    "    elif predicted_sentiment == \"Sad\":\n",
    "        response = \"I'm sorry to hear that you're feeling sad. Is there anything I can do to help?\"\n",
    "    else:\n",
    "        response = \"I'm here to chat with you. How can I assist you today?\"\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rule_based_response_chatbot(user_input):\n",
    "    \n",
    "    predicted_sentiment = predict_sentiment(user_input)\n",
    "    response = generate_rule_based_response(predicted_sentiment)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "Bot: Hello! How can I assist you today?\n",
      "Bot: I'm just a chatbot, but I'm here to help! How can I assist you?\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Bot: I'm here to chat with you. How can I assist you today?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_rule_based_response_chatbot(user_input)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBot: Goodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1261\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1304\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1302\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def generate_pattern_response(user_input):\n",
    "    patterns = {\n",
    "        \"hello\": \"Hello! How can I assist you today?\",\n",
    "        \"how are you\": \"I'm just a chatbot, but I'm here to help! How can I assist you?\",\n",
    "        \"help\": \"Sure, I'd be happy to help. What do you need assistance with?\",\n",
    "        \"bye\": \"Goodbye! If you have more questions in the future, feel free to ask.\",\n",
    "        \n",
    "    }\n",
    "\n",
    "    \n",
    "    for pattern, response in patterns.items():\n",
    "        if pattern in user_input.lower():\n",
    "            return response\n",
    "\n",
    "    \n",
    "    return generate_rule_based_response_chatbot(user_input)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "    bot_response = generate_pattern_response(user_input)\n",
    "    print(\"Bot:\", bot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188378 entries, 0 to 188377\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   conversation_id    188378 non-null  int64 \n",
      " 1   message            188378 non-null  object\n",
      " 2   sentiment          188378 non-null  object\n",
      " 3   processed_message  188378 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "sentiment\n",
      " Curious to dive deeper    80888\n",
      " Neutral                   41367\n",
      " Surprised                 30638\n",
      " Happy                     29617\n",
      " Sad                        2533\n",
      " Disgusted                  1433\n",
      " Fearful                    1026\n",
      " Angry                       876\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(bot_dataset.info())\n",
    "print(bot_dataset[\"sentiment\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
